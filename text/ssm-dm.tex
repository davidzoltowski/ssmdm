\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
% \usepackage{neurips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
  %   \usepackage[final]{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{wrapfig}  % Allow wrapping of text around figures

% import definitions
\input{dzdefs.tex}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{A recurrent state space framework for unifying and generalizing models of decision making dynamics}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
%  David M.~Zoltowski\thanks{Use footnote for providing further information
%    about author (webpage, alternative address)---\emph{not} for acknowledging
%    funding agencies.} \\
%  Princeton Neuroscience Institute\\
%  Princeton University\\
%  Princeton, NJ 08540 \\
%  \texttt{zoltowski@princeton.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
%Here we show how classical models of human and animal behavior and neural activity during decision-making can be instantiated as constrained recurrent state-space models. This allows for interesting generalizations of these models. 
Accumulation of evidence towards a threshold is common feature in models of latent dynamics underlying neural activity and behavior during decision-making. However, the most commonly applied models are restricted to one-dimensional latent dynamics, which are often impoverished both as models of neural activity and of complex behavior. Here we show how accumulation-to-bound models of neural activity can be instantiated as constrained recurrent switching state-space models. In this framework, we then generalize the models to have higher-dimensional latent dynamics and more flexible boundary states and switching criteria. We also introduce the notion of accumulation dimensions as a modular component of state-space models during decision-making. We apply our models to neural recordings from monkey parietal cortices during two different decision-making tasks. 
\end{abstract}

\section{Introduction}

\begin{enumerate}
\item Decision-making dynamics, the dynamics of making a choice
\item Accumulation of evidence models are commonly used to model decision-making dynamics and neural activity
\item However, there are a few things to be desired.
\item Classical models such as the DDM only have 1D latent dynamics and are for tasks with two choices. 
\item the 1D models are often impoverished for explaining neural activity (gain-modulation, non-monotonicity, etc)
\item DDM like models (and ramping models, etc.) often assume IID decision-making trials. We would like to move beyond this (could be future work).
\item Our work overcomes (some?) of these difficulties 
\item We connect the classical DDM (with observations) to a recurrent state-space model. 
\item This connection allows us to generalize accumulation-to-bound models using recurrent SSMs
\item We can expand beyond 1D dynamics and more than 2 choices
\item We can embed accumulation dimensions into larger models
\item We can consider how to model serial dependencies across trials 
\item This is a prime example of constraining models with theory \cite{linderman2017using}
\end{enumerate}

\section{Constraining recurrent state-space models to correspond to accumulation-to-bound}

The models under consideration will in general have the following variables: a $D$-dimensional continuous latent state $x_t \in \mathbb{R}^D$, a set of $K$ discrete latent states $z_t \in \{ 1, 2, ... K \}$, $M$-dimensional inputs $u_t \in \mathbb{R}^M$, and $N$-dimensional observations $y_t \in \mathbb{R}^N$. 

\subsection{rSLDS}
In general, in an rSLDS the discrete state at time $t+1$ depends on the discrete and continuous states at time $t$ and the current input at time $t+1$. We define the rSLDS following the treatment in \cite{linderman2017bayesian}.

The continuous latent state $x_t$ follows linear-Gaussian dynamics that depend on the discrete state $z_t$
\be
x_{t} = A_{z_t} x_{t-1} + V_{z_t} u_t + b_{z_t} + \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0, Q_{z_t})
\ee
where $A_{z_t}, Q_{z_t} \in \mathbb{R}^{D \times D}$, $V_{z_t} \in \mathbb{R}^{D \times M}$, and $b_{z_t} \in \mathbb{R}^D$ for each $z_t$. 

The transition probabilities are given by \textbf{(note right hand side is a vector)}
\be
\log p(z_{t+1} | z_t, x_t, u_{t+1}, R_{z_t}, W_{z_t}, r_{z_t}) \propto R_{z_t} x_t + r_{z_t} + W_{z_t} u_{t+1}
\ee
where the dependence on the continuous state is controlled by $R_{z_t} \in \mathbb{R}^{K \times D}$, the dependence on the input is controlled by $W_{z_t} \in \mathbb{R}^{K \times M}$, and $r_{z_t} \in \mathbb{R}^M$ is a bias that captures dependencies in the discrete states. 


In an rSLDS, the observations are linear mappings from the continuous latent states 
\be
y_t = C_{z_t} x_t + d_{z_t} + \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0, S_{z_t}). 
\ee
However, in general we consider emissions of the form
\be
y_t \sim \mathcal{P}( f( C_{z_t} x_t + d_{z_t} ) ). 
\ee

\subsection{Drift-diffusion model}

The drift-diffusion model is a 1-dimensional dynamics model of choice. It states that $x$ evolves according to a biased random walk. In discrete time, we formalize this as 
\be
x_t = x_{t-1} + \beta_c + \epsilon_t
%dx = \beta_c \, dt + \epsilon_t
\ee
where $\beta_c$ is the strength of the evidence and $\epsilon_t \sim \mathcal{N}(0,\sigma^2)$. If $x$ crosses an upper or lower threshold (bound) at $\pm B$ then the accumulation process stops and $x$ is fixed at $\pm B$. In general, we may have a distribution over the initial value
\be
x_0 \sim \mathcal{N}(\mu_0, \sigma^2_0). 
\ee

We can write this as an rSLDS as follows. The continuous state is a one dimensional variable $x_t \in \mathbb{R}$. There is a discrete state $z_t \in \{\mathsf{ramp}, \mathsf{left bound}, \mathsf{right bound}\}$ that indicates whether the continuous state has reached its threshold (bound). Let $u_t \in \mathbb{R}$ be the input, which specifies the amount of evidence to the left or right choice and which governs the dynamics of $x_t$. 

The model is :
\begin{align}
z_t &\sim p(x_{t-1}) \\
x_t &= x_{t-1} + V_{z_t} u_t + \epsilon_t 
\label{eqn:ddm_dynamics}
\end{align}
where $\epsilon_t \sim \mathcal{N}(0, \sigma^2)$ and the input weights are constrained such that
\begin{align*}
V_{\mathsf{ramp}} &= \beta, \\
V_{\mathsf{left bound}} = V_{\mathsf{right bound}} &= 0.
\end{align*}
The discrete transition probabilities are,
\begin{align*}
\log p(z_t = \textsf{left bound} \mid x_{t-1}) &\propto x_{t-1} - 1 \\
\log p(z_t = \textsf{ramp} \mid x_{t-1}) &\propto 0 \\
\log p(z_t = \textsf{right bound} \mid x_{t-1}) &\propto -x_{t-1} - 1
\end{align*}
We note that we can describe accumulation without a bound simply using a constrained LDS. 

\subsection{Alternative parameterization of DDM with discrete input levels}
In some cases we may have a discrete set of input levels and we may want to learn the mapping from the input category to dynamics. For example, in the random dot motion (RDM) task, the discrete input levels are the different motion coherences and we may want to learn a different drift term for each coherence. 

We can accomplish this by parameterizing $u_t$ as a one-hot vector encoding the stimulus category. If we have $C$ categories, then $u_t$ has $C$ dimensions and $V_{z_t} \in \mathbb{R}^{D \times C}$. We can then learn the elements of $V_{z_t}$, which when $D = 1$ correspond to the drifts for each stimulus category. 

 The dynamics under this parameterization remain the same as in equation~(\ref{eqn:ddm_dynamics}). 

%\susection{We can incorporate other features of 1D Accumulator models}

\subsection{1D Accumulator model}
If we learn the dynamics parameter $A_{z_t}$ for the accumulation state, we can incorporate leaky ($A_{z_t} < 1$) or impulsive ($A_{z_t} > 1$) accumulation to bound. 

\subsection{Brunton model}

TODO: Write adaptation dynamics without coupled LDS?

The 1D accumulator model from \cite{brunton2013rats} has the form
\begin{align*}
x_t &= 
\begin{cases}
0 & \text{if } |x_{t-1}|>B \\
(1 + \lambda) \, x_{t-1} + \left( \delta_{t,t_R} \eta_R c_t - \delta_{t,t_L} \eta_L c_t \right) + \epsilon_t & \text{otherwise}
\end{cases}
\end{align*}
where $\epsilon_t \sim \mathcal{N}(0,\sigma_a^2)$, $\eta_R \sim \mathcal{N}(1, \sigma_s^2)$, $\eta_L \sim \mathcal{N}(1, \sigma_s^2)$ and 
\begin{align*}
c_t &= \left[ \frac{\tau_\varphi - 1}{\tau_\varphi} + (\varphi - 1) (\delta_{t,t_R} + \delta_{t,t_L}) \right] c_{t-1} + \frac{1}{\tau_\varphi}.
\end{align*}
The boundary $B$ acts in the same mechanism as the boundary in the DDM. The initial value $x_0$ comes from a zero-mean normal distribution with variance $\sigma_i^2$.

We can write the dynamics in the accumulation state (before boundary) with a coupled LDS
\begin{align*}
x_0 & \sim \mathcal{N}(0, \sigma_i^2) \\
x_t & \sim \mathcal{N} \bigg((1 + \lambda) \, x_{t-1} + ( \delta_{t,t_R} -  \delta_{t,t_L} ) c_t , \, \sigma_a^2 + (\delta_{t,t_R}^2 + \delta_{t,t_L}^2)\,  c_t^2 \, \sigma_s^2 \bigg)\\
c_t & \sim \mathcal{N} \bigg(\left[ \frac{\tau_\varphi - 1}{\tau_\varphi} + (\varphi - 1) (\delta_{t,t_R} + \delta_{t,t_L}) \right] c_{t-1} + \frac{1}{\tau_\varphi}, \, \sigma_c^2 \bigg).
\end{align*}
We recover the model in \cite{brunton2013rats} with $\sigma_c^2 \rightarrow 0$. Though we note it may not be necessary to write this as a coupled LDS, since the entire trajectory of $c_t$ throughout a trial is known when conditioned on the input and parameters. 

DePasquale et al., Cosyne 2019.

\section{Multi-dimensional accumulator models}

In many situations, it is natural to model behavior with more than two choices or more than one latent accumulation dimension. In the recurrent state space modeling framework, it is (likewise) natural to increase the dimensionality of the latent variables to accommodate these modeling desiderata. For example, we can simply increase the dimensionality of the latent continuous state to $D$-dimensions to model $D$ accumulators, where the dynamics remain described by
\be
x_t = A_{z_t} x_{t-1} + V_{z_t} u_t + \epsilon_t.
\ee
A specific example of this is where in the accumulation state both $A_{z_t}$ and $V_{z_t}$ are identity matrices and $u_t$ is a $D$-dimensional vector with the input evidence for each dimension. 

One can also adapt the number of discrete latent states and the parameterization of the transitions to the discrete latent states. 

\subsection{Illustrative example: two accumulators with Poisson observations}
For example, we may wish to model a task with a binary choice (say, left $L$ or right $R$) and two input streams which provide evidence supporting one of the choices. In the ``accumulation'' state we will model the latent continuous dynamics with
\be
\begin{bmatrix}
x_R \\
x_L
\end{bmatrix}_{t}
= 
\begin{bmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22} 
\end{bmatrix}
\begin{bmatrix}
x_R \\
x_L
\end{bmatrix}_{t-1}
+
\begin{bmatrix}
v_{11} & 0 \\
0 & v_{22} 
\end{bmatrix}
\begin{bmatrix}
u_R \\
u_L 
\end{bmatrix}_{t-1}
+ \epsilon_t, 
\quad 
\epsilon_t \sim \mathcal{N} \bigg(0, \begin{bmatrix} q_{11} & q_{12} \\ q_{21} & q_{22} \end{bmatrix} \bigg).
\ee
If we set $a_{12} = a_{21} = 0$, then the dimensions of $x$ separately accumulate the two streams of inputs. The diagonal terms of the dynamics $a_{11}$ and $a_{22}$ allow for modeling of leaky or impulsive dynamics, which may be separate for the two evidence streams. The process noise could have the same or different marginal variances for each dimension and it could be either correlated or uncorrelated across the two dimensions. For simplicity, we will first consider a model with uncorrelated noise $q_{12} = q_{21} = 0$. 

The latent dimensions map to observed neural activity via
\be
y_t | x_t \sim \mathrm{Poisson}(f(C x_t + d))
\ee
where $f()$ may be a softplus or exponential nonlinearity. One key property of this formalization is that now the observations can depend on any linear combination of the latent dimensions. For example, some neurons may weight heavily onto $x_R$, others onto $x_L$, and finally others onto $x_R - x_L$ (or $x_L - x_R$). This added flexibility could be useful for explaining and understanding neural activity, as one-dimensional accumulator models typically make the assumption that neural activity represents only a difference such as $x_R - x_L$. 

We consider here two options for the discrete states and discrete state transitions. In both cases, we will have three discrete states: the accumulation state and R and L decision states. The dynamics in the decision states are described with $A_{z_t} = I$ and $V_{z_t} = 0$. 

\subsubsection{Collapse to 1D decision states}
With discrete transition probabilities 
\begin{align*}
\log p(z_t = \text{R} \mid x_{t-1}) &\propto \gamma (x_{R,t-1} - x_{L,t-1}) - \gamma \\
\log p(z_t = \text{accum} \mid x_{t-1}) &\propto 0 \\
\log p(z_t = \text{L} \mid x_{t-1}) &\propto \gamma (x_{L,t-1} - x_{R,t-1}) - \gamma 
\end{align*}
the transitions between discrete states collapses to the transitions in the 1D accumulator model (that is, it only depends on the difference of the accumulated input), where $\gamma$ is a scale parameter that controls the sharpness of the transition boundaries. 

\subsubsection{Race model}
We could instantiate a race model of competing accumulators \cite{gold2007neural} with 
\begin{align*}
\log p(z_t = \text{R} \mid x_{t-1}) &\propto \gamma x_{R,t-1} - \gamma \\
\log p(z_t = \text{accum} \mid x_{t-1}) &\propto 0 \\
\log p(z_t = \text{L} \mid x_{t-1}) &\propto \gamma x_{L,t-1} - \gamma.
\end{align*}
If $\gamma$ is relatively large, then the most important factor in the transitions is which of $x_R$ or $x_L$ surpasses unity first.

This model could also be useful for modeling the responses of a single population of neurons with a single input. Specifically, it allows for modeling an integration offset time that differs on each trial, even when the dimension representing the neural population is decreasing (see \cite{latimer2017no} and zoltowski 2019). In this case, both latent dimensions will depend on the single input except with different signs (e.g. $v_1 = - v_2$). The neural activity will only depend on one of the latent dimensions. The state transition structure could allow learning of random integration offset times on each trial (\textbf{try to fit this to simulations from the supplementary figures of the Neuron paper?}). 

\subsubsection{Augmented input}
We could learn a filtered mapping of the input by augmenting the input space. For example, we could set the input term in the dynamics to
\be
V 
\begin{bmatrix}
u_{r,t-1} \\ u_{l,t-1} \\ u_{r,t-2} \\ u_{r,t-2} \\ u_{r,t-3} \\ u_{l,t-3} 
\end{bmatrix}.
\ee
The inferred matrix $V$ could zero out the most recent inputs and learn a time delay between neural activity and input dynamics. Expanding on this direction and learning a more complicated filtering of the inputs is an interesting direction of work. 

\section{Accumulation dimensions: a modular component embedded in models}
The 1D models of choice may be impoverished for fitting neural activity. For example, neural activity may fluctuate slowly across trials, and it may show non-monotonic trends that are not captured by the accumulation to bound hypothesis. In this framework, it is natural to include additional dimensions for explaining neural activity. 

\subsection{Accumulation-to-bound embedded in a dynamical system, possibly followed by additional dynamics}
We may be interested in models where after the accumulation-to-bound process, neural activity undergoes additional dynamics subject to working memory or movements. 
- dimensions that are zero throughout initial trial, then kick-in afterwards?

\subsection{Gain modulation (exponential nonlinearity)}
Let $x_t$ be the continuous state in an accumulation model described above. For models with Poisson observations, we can incorporate gain modulation \cite{goris2017dissociation} with
\begin{align}
g_0 & \sim \mathcal{N}(\mu_g, \sigma_g^2) \\
g_t | g_{t-1} & \sim \mathcal{N}(g_{t-1}, \sigma_g^2) \\
y_t | x_t, g_t & \sim \mathrm{Poisson}(\exp(C x_t + \mathrm{1} g_t))
\end{align}
were $\mathrm{1}$ is a $N$-dimensional (number of observations) vector of ones such that the gain variable $g$ represents global fluctuations.  


%\section{More than just accumulation and boundary states}
%We could model 1) switches between accumulating and not-accumulating within a trial and 2) a random integration onset time in which integration does not necessarily start at the beginning of every analysis period. 
%
%\section{Beyond single-trials or single-choices \cite{huk2018beyond}}
%Models assume independent trials. We can be more flexible than this. 
%
%Fitting across trials - GLM dependent starting value, related to switching between accumulation or not, with resets?
%The reset accumulator model, fit across trials, allows you to ask if at the start of each trial does the decision-variable reset, or is / what is the dependence on the ending accumulator model from the last trial. ?
%
%\subsection{Sequential choice models (sequential accumulation models}
%
%\subsection{Reset accumulator model}
%We add an additional reset state. In the reset state, the continuous latent variable is independent of the previous latent variable
%\be
%x_t \sim \mathcal{N}(0 x_{t-1} + \mu_0, Q_0).
%\ee
%The transition probabilities could be setup such that the model transitions to the reset state after making a choice. 
%
%\section{Models of choice and behavior only}
%
%Model reaction-time, action-selection, and more? 
%\begin{enumerate}
%\item Another latent dimension could specify exploration vs. exploitation / biases of behavior. For example, could be a latent that is a bias on the choice probability or other choice readouts. 
%\item Ideas: fit to behavioral correlates of decision, potentially continuous throughout the trial. Could be nonlinear mappings from latent dynamics to behavioral measurements.
%\end{enumerate}
%
%\section{Other modeling extensions}
%\begin{itemize}
%\item Learning mapping from inputs to latents (e.g. what time-lag?). Here, let $V_{z_t}$ be a filter on the inputs... learn time-scale of mappings from input to latents. 
%\item Stepping vs. ramping models.Have two-dimensions. One is an accumulation to bound process, while the other has no dynamics - just have state-dependent rates. The first dimension is ramping while the second dimension is stepping. Each neuron can have a linear readout from the two dimensions. The weight on each dimension corresponds to how much a neuron weights onto ramping or stepping! 
%\item Incorporate GLM observations on top of latents? 
%\end{itemize}

\section{Inference}

\subsection{Variational Inference}

\subsection{Variational Laplace-EM (cite Chong Wang, Variational Inference in Nonconjugate Models}

\subsection{Initialization}
Given observations $y$, use factor analysis to compute $y \approx C \hat{x} + \mu$. Then find an affine transformation of $\hat{x}$ that maximizes the prior probability of the transformed $\hat{x}$ under the model 
\be
\hat{R}, \hat{r} = \argmax_{ R, r } \log p(x = R \hat{x} + r | \theta_\text{AR-HMM}) .
\ee
Use $\hat{R}$ and $\hat{r}$ to transform $C$, $\hat{x}$, and $\mu$.

\section{Related work}
\begin{itemize}
\item The DDM \cite{ratcliff2008diffusion,gold2007neural}
\item Theory-constrained state space models \cite{linderman2017using}
\item Proposal of thinking ``beyond trial-based paradigms'' with review of relevant literature \cite{huk2018beyond}. The authors in  \cite{huk2018beyond} propose to integrate continuous neural activity measurements with behavior. This work could be useful for analyzing decision-making or action selection correlates across trials.
\item Example of Kalman filtering being used in ``continuous psychophysics" \cite{bonnen2015continuous}.
\item Ramping and stepping models: 1-dimensional latent variable models of neural activity in decision-making \cite{latimer2015single}, \textbf{Zoltowski et al., 2019}. 
\end{itemize}

\section{Discussion}


\subsubsection*{Acknowledgments}
%ACKNOWLEDGE T32!

%Use unnumbered third level headings for the acknowledgments. All acknowledgments
%go at the end of the paper. Do not include acknowledgments in the anonymized
%submission, only in the final paper.

\section*{References}

%References follow the acknowledgments. Use unnumbered first-level heading for
%the references. Any choice of citation style is acceptable as long as you are
%consistent. It is permissible to reduce the font size to \verb+small+ (9 point)
%when listing the references. {\bf Remember that you can use more than eight
%  pages as long as the additional pages contain \emph{only} cited references.}
\medskip

\small
\bibliographystyle{plain}
%\bibliographystyle{apalike}
\bibliography{dzbib.bib}

\end{document}
